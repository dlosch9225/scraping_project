# ğŸŒ Multi-Source Data Scraper

This Python project automatically scrapes and stores daily data from multiple public sources:
- ğŸ’° **Bitcoin price** from CoinGecko  
- ğŸŒ¤ï¸ **Weather data** from Open-Meteo  
- ğŸŒ **Earthquake alerts** from USGS

Data is saved in both **CSV** and **HDF5** formats. A scheduler runs the scraper daily during a 9-day window. Logs and visualizations are included.

---

## ğŸ“š Table of Contents

- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Automation](#automation)
- [Data Storage Format](#data-storage-format)
- [Data Structure](#data-structure)
- [Visualization](#visualization)
- [Testing & Validation](#testing--validation)
- [Known Limitations](#known-limitations)
- [Requirements](#requirements)
- [License](#license)

---

## âœ¨ Features

- â±ï¸ **Automated daily scraping** at 11:00 AM (via `cron`)
- ğŸ’¾ **Dual storage**: CSV + HDF5 with deduplication
- ğŸ“Š **Clean and styled visualizations** with Matplotlib
- ğŸ§  **Retry logic** and **error handling** for API calls
- ğŸ§ª Modular, testable, and easy to expand

---

## ğŸ—ï¸ Project Structure

```
scraping_project/
â”œâ”€â”€ data/                    # CSVs and HDF5 data storage
â”œâ”€â”€ logs/                    # All logs + scheduler state
â”œâ”€â”€ scrapers/               # Core scraping logic
â”‚   â”œâ”€â”€ scraper.py
â”‚   â”œâ”€â”€ data_utils.py
â”œâ”€â”€ plotting/               # All plots and visualizations
â”‚   â”œâ”€â”€ plot_bitcoin.py
â”‚   â”œâ”€â”€ open_meteo.py
â”‚   â”œâ”€â”€ plot_usgs.py
â”œâ”€â”€ scripts/                # Utility/debugging scripts
â”‚   â”œâ”€â”€ force_update_hdf5.py
â”‚   â”œâ”€â”€ inspect_hdf5.py
â”œâ”€â”€ scheduler.py            # Daily job manager
â”œâ”€â”€ start_scheduler.sh      # Script launched by cron
â”œâ”€â”€ storage.py              # HDF5 logic
â”œâ”€â”€ requirements.txt
â””â”€â”€ websites.csv            # Metadata of scraped sources
```

## âš™ï¸ Installation

#### 1.  the repo:
```
git clone https://github.com/your_username/scraping_project.git
cd scraping_project
```

#### 2. Create a virtual environment:
```
python3 -m venv .venv
source .venv/bin/activate
```

#### 3. Install dependencies:
```
pip install -r requirements.txt
```
## ğŸš€ Usage

Run the scraper manually:
```
python scrapers/scraper.py
```

Or run the visualization:
```
python plotting/plot_bitcoin.py
```
## â° Automation

The project uses cron to:

* Start the scheduler at system reboot
* Trigger scrapers daily at 11:00 AM

#### Cron Configuration Example (macOS/Linux)
```
@reboot /absolute/path/to/start_scheduler.sh
0 11 * * * /absolute/path/to/start_scheduler.sh
```

Ensure:

* start_scheduler.sh is executable (chmod +x)
* The Python virtual environment path is correct
* System is awake at 11:00 AM

## ğŸ’¾ Data Storage Format

The project uses both CSV and HDF5 for persistent storage.

### Why HDF5?

* ğŸ” Fast reading/writing of large tables
* ğŸ“… Easy time-based filtering
* ğŸ”’ Deduplication by date
* ğŸ”— Integrated with pandas.HDFStore

#### HDF5 File Structure

| Data Source      | HDF5 Key      | CSV File              |
| ---------------- | ------------- | --------------------- |
| CoinGecko BTC    | `bitcoin`     | `data/bitcoin.csv`    |
| Open-Meteo       | `weather`     | `data/open_meteo.csv` |
| USGS Earthquakes | `earthquakes` | `data/usgs.csv`       |

## ğŸ—‚ Data Structure Example

Example row from open_meteo.csv:

| date       | temperature | wind_speed | weather_code | source         |
| ---------- | ----------- | ---------- | ------------ | -------------- |
| 2025-10-27 | 7.8         | 17.9       | 61           | Open-Meteo API |

## ğŸ“Š Visualization

Once data is collected over multiple days, the following graphs are generated:

| Plot                    | Script                     |
| ----------------------- | -------------------------- |
| ğŸ“ˆ Bitcoin Price Trend  | `plotting/plot_bitcoin.py` |
| ğŸŒ¡ï¸ Temp/Wind in Berlin | `plotting/open_meteo.py`   |
| ğŸŒ Daily Earthquakes    | `plotting/plot_usgs.py`    |

Each chart includes:

* ğŸ“… Date-based X-axis
* ğŸ·ï¸ Proper labeling and units (e.g., $, Â°C, magnitude)
* ğŸ¯ Clean aesthetics and layout
* ğŸ” Fallback to .csv if HDF5 fails

## ğŸ§ª Testing & Validation

* Manual insertion of synthetic data for plotting
* Tested fallback to CSV when HDF5 unavailable
* Verified scheduler triggers scraping
* Handled API downtime with retry logic
* Verified deduplication in CSV and HDF5

## â— Known Limitations

* ğŸ’¡ System must be on (not sleeping) at 11:00 AM for cron to run
* ğŸ”Œ Internet connection required for scraping APIs
* ğŸ§  Requires periodic check of scheduler_state.txt
* ğŸ› ï¸ Scheduler state does not reset automatically after 9 days

## ğŸ“¦ Requirements

Install via:
```
pip install -r requirements.txt
```
#### Core Dependencies
```
beautifulsoup4==4.14.2
certifi==2025.10.5
charset-normalizer==3.4.4
contourpy==1.3.3
cycler==0.12.1
fonttools==4.60.1
h5py==3.15.1
idna==3.11
kiwisolver==1.4.9
matplotlib==3.10.7
numpy==2.3.4
packaging==25.0
pandas==2.3.3
pandas-stubs==2.3.2.250926
pillow==12.0.0
pyparsing==3.2.5
python-dateutil==2.9.0.post0
pytz==2025.2
requests==2.32.5
schedule==1.2.2
seaborn==0.13.2
six==1.17.0
soupsieve==2.8
typing_extensions==4.15.0
tzdata==2025.2
urllib3==2.5.0
```
## ğŸ“„ License

This project was developed for the academic module:
\
Data Quality and Data Wrangling

Python and SQL Programming and Data Analysis
\
IU Internationale Hochschule Akademie

The code is intended strictly for educational use and assessment.
\
Unauthorized reproduction or redistribution is not permitted.

## ğŸ“¬ Contact
Created by Diana Losch
ğŸ”— GitHub: @dlosch9225